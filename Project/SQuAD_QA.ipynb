{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import collections\n",
    "import json\n",
    "import unicodedata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unicode(text):\n",
    "    \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n",
    "    if six.PY3:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, bytes):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    elif six.PY2:\n",
    "        if isinstance(text, str):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        elif isinstance(text, unicode):\n",
    "            return text\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    else:\n",
    "        raise ValueError(\"Not running on Python2 or Python 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}\n",
    "with open(\"/Users/vijay/MIDS/W266/Project/AnsweringMachines/glove.6B.300d.txt\") as fp:\n",
    "    for line in fp:\n",
    "        e = line.split(\" \")\n",
    "        word = e[0]\n",
    "        embeddings = np.array(e[1:])\n",
    "        if word not in embedding_dict:\n",
    "            embedding_dict[word] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle \"[CLS]\" and \"[SEP]\"\n",
    "embedding_dict['[CLS]'] = np.random.uniform(0, 1, 300)\n",
    "embedding_dict['[SEP]'] = np.random.uniform(0, 1, 300)\n",
    "embedding_dict['[UNK]'] = np.random.uniform(0, 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab():\n",
    "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "    vocab = collections.OrderedDict()\n",
    "    index = 0\n",
    "    for k in embedding_dict.keys():\n",
    "        token = convert_to_unicode(k)\n",
    "        if not token:\n",
    "            break\n",
    "        token = token.strip()\n",
    "        vocab[token] = index\n",
    "        index += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unusual'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_vocab[3217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400003"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_control(char):\n",
    "    \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
    "    # These are technically control characters but we count them as whitespace\n",
    "    # characters.\n",
    "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return False\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"C\"):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_punctuation(char):\n",
    "    \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n",
    "    cp = ord(char)\n",
    "    # We treat all non-letter/number ASCII as punctuation.\n",
    "    # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
    "    # Punctuation class but we treat them as punctuation anyways, for\n",
    "    # consistency.\n",
    "    if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
    "        (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"P\"):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_whitespace(char):\n",
    "    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
    "    # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
    "    # as whitespace since they are generally considered as such.\n",
    "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat == \"Zs\":\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTokenizer(object):\n",
    "    \"\"\"Runs basic tokenization (punctuation splitting, lower casing, etc.).\"\"\"\n",
    "\n",
    "    def __init__(self, do_lower_case=True):\n",
    "        \"\"\"Constructs a BasicTokenizer.\n",
    "\n",
    "        Args:\n",
    "          do_lower_case: Whether to lower case the input.\n",
    "        \"\"\"\n",
    "        self.do_lower_case = do_lower_case\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenizes a piece of text.\"\"\"\n",
    "        text = convert_to_unicode(text)\n",
    "        text = self._clean_text(text)\n",
    "\n",
    "        # This was added on November 1st, 2018 for the multilingual and Chinese\n",
    "        # models. This is also applied to the English models now, but it doesn't\n",
    "        # matter since the English models were not trained on any Chinese data\n",
    "        # and generally don't have any Chinese data in them (there are Chinese\n",
    "        # characters in the vocabulary because Wikipedia does have some Chinese\n",
    "        # words in the English Wikipedia.).\n",
    "        text = self._tokenize_chinese_chars(text)\n",
    "\n",
    "        orig_tokens = whitespace_tokenize(text)\n",
    "        split_tokens = []\n",
    "        for token in orig_tokens:\n",
    "            if self.do_lower_case:\n",
    "                token = token.lower()\n",
    "            token = self._run_strip_accents(token)\n",
    "            split_tokens.extend(self._run_split_on_punc(token))\n",
    "\n",
    "        output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n",
    "        return output_tokens\n",
    "\n",
    "    def _run_strip_accents(self, text):\n",
    "        \"\"\"Strips accents from a piece of text.\"\"\"\n",
    "        text = unicodedata.normalize(\"NFD\", text)\n",
    "        output = []\n",
    "        for char in text:\n",
    "            cat = unicodedata.category(char)\n",
    "            if cat == \"Mn\":\n",
    "                continue\n",
    "            output.append(char)\n",
    "        return \"\".join(output)\n",
    "\n",
    "    def _run_split_on_punc(self, text):\n",
    "        \"\"\"Splits punctuation on a piece of text.\"\"\"\n",
    "        chars = list(text)\n",
    "        i = 0\n",
    "        start_new_word = True\n",
    "        output = []\n",
    "        while i < len(chars):\n",
    "            char = chars[i]\n",
    "            if _is_punctuation(char):\n",
    "                output.append([char])\n",
    "                start_new_word = True\n",
    "            else:\n",
    "                if start_new_word:\n",
    "                    output.append([])\n",
    "                    start_new_word = False\n",
    "            output[-1].append(char)\n",
    "            i += 1\n",
    "\n",
    "        return [\"\".join(x) for x in output]\n",
    "\n",
    "    def _tokenize_chinese_chars(self, text):\n",
    "        \"\"\"Adds whitespace around any CJK character.\"\"\"\n",
    "        output = []\n",
    "        for char in text:\n",
    "            cp = ord(char)\n",
    "            if self._is_chinese_char(cp):\n",
    "                output.append(\" \")\n",
    "                output.append(char)\n",
    "                output.append(\" \")\n",
    "            else:\n",
    "                output.append(char)\n",
    "        return \"\".join(output)\n",
    "\n",
    "    def _is_chinese_char(self, cp):\n",
    "        \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n",
    "        # This defines a \"chinese character\" as anything in the CJK Unicode block:\n",
    "        #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n",
    "        #\n",
    "        # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n",
    "        # despite its name. The modern Korean Hangul alphabet is a different block,\n",
    "        # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n",
    "        # space-separated words, so they are not treated specially and handled\n",
    "        # like the all of the other languages.\n",
    "        if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n",
    "            (cp >= 0x3400 and cp <= 0x4DBF) or  #\n",
    "            (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n",
    "            (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n",
    "            (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n",
    "            (cp >= 0x2B820 and cp <= 0x2CEAF) or\n",
    "            (cp >= 0xF900 and cp <= 0xFAFF) or  #\n",
    "            (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "        output = []\n",
    "        for char in text:\n",
    "            cp = ord(char)\n",
    "            if cp == 0 or cp == 0xfffd or _is_control(char):\n",
    "                continue\n",
    "            if _is_whitespace(char):\n",
    "                output.append(\" \")\n",
    "            else:\n",
    "                output.append(char)\n",
    "        return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace_tokenize(text):\n",
    "    \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordpieceTokenizer(object):\n",
    "    \"\"\"Runs WordPiece tokenziation.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n",
    "        self.vocab = vocab\n",
    "        self.unk_token = unk_token\n",
    "        self.max_input_chars_per_word = max_input_chars_per_word\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenizes a piece of text into its word pieces.\n",
    "\n",
    "        This uses a greedy longest-match-first algorithm to perform tokenization\n",
    "        using the given vocabulary.\n",
    "\n",
    "        For example:\n",
    "          input = \"unaffable\"\n",
    "          output = [\"un\", \"##aff\", \"##able\"]\n",
    "\n",
    "        Args:\n",
    "          text: A single token or whitespace separated tokens. This should have\n",
    "            already been passed through `BasicTokenizer.\n",
    "\n",
    "        Returns:\n",
    "          A list of wordpiece tokens.\n",
    "        \"\"\"\n",
    "\n",
    "        text = convert_to_unicode(text)\n",
    "\n",
    "        output_tokens = []\n",
    "        for token in whitespace_tokenize(text):\n",
    "            chars = list(token)\n",
    "            if len(chars) > self.max_input_chars_per_word:\n",
    "                output_tokens.append(self.unk_token)\n",
    "                continue\n",
    "\n",
    "            is_bad = False\n",
    "            start = 0\n",
    "            sub_tokens = []\n",
    "            while start < len(chars):\n",
    "                end = len(chars)\n",
    "                cur_substr = None\n",
    "                while start < end:\n",
    "                    substr = \"\".join(chars[start:end])\n",
    "                    if start > 0:\n",
    "                        substr = \"##\" + substr\n",
    "                    if substr in self.vocab:\n",
    "                        cur_substr = substr\n",
    "                        break\n",
    "                    end -= 1\n",
    "                if cur_substr is None:\n",
    "                    is_bad = True\n",
    "                    break\n",
    "                sub_tokens.append(cur_substr)\n",
    "                start = end\n",
    "\n",
    "            if is_bad:\n",
    "                output_tokens.append(self.unk_token)\n",
    "            else:\n",
    "                output_tokens.extend(sub_tokens)\n",
    "\n",
    "        return output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = WordpieceTokenizer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['islet']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpt.tokenize(\"islet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printable_text(text):\n",
    "    \"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\"\n",
    "\n",
    "    # These functions want `str` for both Python2 and Python3, but in one case\n",
    "    # it's a Unicode string and in the other it's a byte string.\n",
    "    if six.PY3:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, bytes):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    elif six.PY2:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, unicode):\n",
    "            return text.encode(\"utf-8\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    else:\n",
    "        raise ValueError(\"Not running on Python2 or Python 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\n",
    "\n",
    "        For examples without an answer, the start and end position are -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               qas_id,\n",
    "               question_text,\n",
    "               doc_tokens,\n",
    "               orig_answer_text=None,\n",
    "               start_position=None,\n",
    "               end_position=None,\n",
    "               is_impossible=False):\n",
    "        self.qas_id = qas_id\n",
    "        self.question_text = question_text\n",
    "        self.doc_tokens = doc_tokens\n",
    "        self.orig_answer_text = orig_answer_text\n",
    "        self.start_position = start_position\n",
    "        self.end_position = end_position\n",
    "        self.is_impossible = is_impossible\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        s += \"qas_id: %s\" % (printable_text(self.qas_id))\n",
    "        s += \", question_text: %s\" % (\n",
    "            printable_text(self.question_text))\n",
    "        s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
    "        if self.start_position:\n",
    "            s += \", original_answer: [%s]\" % (\" \".join(self.orig_answer_text))\n",
    "        if self.start_position:\n",
    "            s += \", start_position: %d\" % (self.start_position)\n",
    "        if self.start_position:\n",
    "            s += \", end_position: %d\" % (self.end_position)\n",
    "        if self.start_position:\n",
    "            s += \", is_impossible: %r\" % (self.is_impossible)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_squad_examples(input_file, is_training):\n",
    "    \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
    "    with open(input_file, \"r\") as reader:\n",
    "        input_data = json.load(reader)[\"data\"]\n",
    "\n",
    "    def is_whitespace(c):\n",
    "        if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    show_first = False\n",
    "    examples = []\n",
    "    paragraphs = []\n",
    "    for entry in input_data:\n",
    "        for paragraph in entry[\"paragraphs\"]:\n",
    "            paragraph_text = paragraph[\"context\"]\n",
    "            paragraphs.append(paragraph_text)\n",
    "            doc_tokens = []\n",
    "            char_to_word_offset = []\n",
    "            prev_is_whitespace = True\n",
    "            not_in_vocab = 0\n",
    "            for c in paragraph_text:\n",
    "                if is_whitespace(c):\n",
    "                    prev_is_whitespace = True\n",
    "                else:\n",
    "                    if prev_is_whitespace:\n",
    "                        if c.lower() not in vocab:\n",
    "                            not_in_vocab += 1\n",
    "                        doc_tokens.append(c)\n",
    "                    else:\n",
    "                        doc_tokens[-1] += c\n",
    "                    prev_is_whitespace = False\n",
    "                char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "\n",
    "            if not_in_vocab > 5:\n",
    "                print(paragraph_text)\n",
    "                \n",
    "            if show_first:\n",
    "                show_first = False\n",
    "                print(\"Paragraph: {:s}\".format(paragraph_text))\n",
    "                print(char_to_word_offset)\n",
    "                print(doc_tokens)\n",
    "            \n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                qas_id = qa[\"id\"]\n",
    "                question_text = qa[\"question\"]\n",
    "                start_position = None\n",
    "                end_position = None\n",
    "                orig_answer_text = None\n",
    "                is_impossible = False\n",
    "                \n",
    "                if is_training:\n",
    "\n",
    "                    if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
    "                        raise ValueError(\n",
    "                            \"For training, each question should have exactly 1 answer.\")\n",
    "                    if not is_impossible:\n",
    "                        answer = qa[\"answers\"][0]\n",
    "                        orig_answer_text = answer[\"text\"]\n",
    "                        answer_offset = answer[\"answer_start\"]\n",
    "                        answer_length = len(orig_answer_text)\n",
    "                        start_position = char_to_word_offset[answer_offset]\n",
    "                        end_position = char_to_word_offset[answer_offset + answer_length - 1]\n",
    "\n",
    "                        # Only add answers where the text can be exactly recovered from the\n",
    "                        # document. If this CAN'T happen it's likely due to weird Unicode\n",
    "                        # stuff so we will just skip the example.\n",
    "                        #\n",
    "                        # Note that this means for training mode, every example is NOT\n",
    "                        # guaranteed to be preserved.\n",
    "                        actual_text = \" \".join(\n",
    "                            doc_tokens[start_position:(end_position + 1)])\n",
    "                        cleaned_answer_text = \" \".join(\n",
    "                            whitespace_tokenize(orig_answer_text))\n",
    "                        #if actual_text.find(cleaned_answer_text) == -1:\n",
    "                        #  tf.logging.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
    "                        #                     actual_text, cleaned_answer_text)\n",
    "                        #  continue\n",
    "                    else:\n",
    "                        start_position = -1\n",
    "                        end_position = -1\n",
    "                        orig_answer_text = \"\"\n",
    "\n",
    "                example = SquadExample(\n",
    "                    qas_id=qas_id,\n",
    "                    question_text=question_text,\n",
    "                    doc_tokens=doc_tokens,\n",
    "                    orig_answer_text=orig_answer_text,\n",
    "                    start_position=start_position,\n",
    "                    end_position=end_position,\n",
    "                    is_impossible=is_impossible)\n",
    "                \n",
    "                examples.append(example)\n",
    "\n",
    "    return examples, paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winters are cold and damp, and prevailing wind patterns that blow offshore minimize the moderating effects of the Atlantic Ocean; yet the Atlantic and the partial shielding from colder air by the Appalachians keep the city warmer in the winter than inland North American cities at similar or lesser latitudes such as Pittsburgh, Cincinnati, and Indianapolis. The daily mean temperature in January, the area's coldest month, is 32.6 °F (0.3 °C); however, temperatures usually drop to 10 °F (−12 °C) several times per winter, and reach 50 °F (10 °C) several days each winter month. Spring and autumn are unpredictable and can range from chilly to warm, although they are usually mild with low humidity. Summers are typically warm to hot and humid, with a daily mean temperature of 76.5 °F (24.7 °C) in July and an average humidity level of 72%. Nighttime conditions are often exacerbated by the urban heat island phenomenon, while daytime temperatures exceed 90 °F (32 °C) on average of 17 days each summer and in some years exceed 100 °F (38 °C). In the warmer months, the dew point, a measure of atmospheric moisture, ranges from 57.3 °F (14.1 °C) in June to 62.0 °F (16.7 °C) in August. Extreme temperatures have ranged from −15 °F (−26 °C), recorded on February 9, 1934, up to 106 °F (41 °C) on July 9, 1936.\n",
      "The island covers an area of 25 square kilometres (2,500 ha). The eastern side is wetter than the western. Although the climate is essentially arid, the rainfall does average 1000 mm annually, but with considerable variation over the terrain. Summer is from May to November, which is also the rainy season. Winter from December to April is the dry season. Sunshine is very prominent for nearly the entire year and even during the rainy season. Humidity, however, is not very high due to the winds. The average temperature is around 25 °C with day temperatures rising to 32 °C. The average high and low temperatures in January are 28 °C and 22 °C, respectively, while in July they are 30 °C and 24 °C. The lowest night temperature recorded is 13 °C. The Caribbean sea waters in the vicinity generally maintain a temperature of about 27 °C.\n",
      "Since the country is located on the Equator, the climate is consistent year-round, with the average day temperature being a humid 24 °C (75 °F) and nights generally between 16 °C (61 °F) and 21 °C (70 °F). The average yearly rainfall ranges from 1,100 millimetres (43 in) in south in the Niari Valley to over 2,000 millimetres (79 in) in central parts of the country. The dry season is from June to August while in the majority of the country the wet season has two rainfall maxima: one in March–May and another in September–November.\n",
      "In a number of countries, although being today generally considered similar institutions of higher learning across many countries, polytechnics and institutes of technology used to have a quite different statute among each other, its teaching competences and organizational history. In many cases polytechnic were elite technological universities concentrating on applied science and engineering and may also be a former designation for a vocational institution, before it has been granted the exclusive right to award academic degrees and can be truly called an institute of technology. A number of polytechnics providing higher education is simply a result of a formal upgrading from their original and historical role as intermediate technical education schools. In some situations, former polytechnics or other non-university institutions have emerged solely through an administrative change of statutes, which often included a name change with the introduction of new designations like institute of technology, polytechnic university, university of applied sciences, or university of technology for marketing purposes. Such emergence of so many upgraded polytechnics, former vocational education and technical schools converted into more university-like institutions has caused concern where the lack of specialized intermediate technical professionals lead to industrial skill shortages in some fields, being also associated to an increase of the graduate unemployment rate. This is mostly the case in those countries, where the education system is not controlled by the state and everybody can grant degrees.[citation needed] Evidence have also shown a decline in the general quality of teaching and graduate's preparation for the workplace, due to the fast-paced conversion of that technical institutions to more advanced higher level institutions. Mentz, Kotze and Van der Merwe (2008) argues that all the tools are in place to promote the debate on the place of technology in higher education in general and in Universities of Technology specifically. The aspects of this debate can follow the following lines: • To what degree is technology defined as a concept? • What is the scope of technology discourse? • What is the place and relation of science with technology? • How useful is the Mitcham framework in thinking about technology in South Africa? • Can a measure of cooperation as opposed to competition be achieved amongst higher education institutions? • Who ultimately is responsible for vocational training and what is the role of technology in this?\n",
      "Along with the rest of South West England, Plymouth has a temperate oceanic climate (Köppen Cfb) which is generally wetter and milder than the rest of England. This means a wide range of exotic plants can be grown. The annual mean temperature is approximately 11 °C (52 °F). Due to the modifying effect of the sea the seasonal range is less than in most other parts of the UK. As a result of this summer highs are lower than its southerly latitude should warrant, but as a contrast the coldest month of February has mean minimum temperatures as mild as between 3 and 4 °C (37 and 39 °F). Snow is rare, not usually equating to more than a few flakes, but there have been exclusions, namely the European winter storms of 2009-10 which, in early January, covered Plymouth in at least 1 inch (2.5 cm) of snow; more on higher ground. Another period of notable snow occurred from 17–19 December 2010 when up to 8 inches (20 cm) of snow fell through the period – though only 2 inches (5.1 cm) would lie at any one time due to melt. Over the 1961–1990 period, annual snowfall accumulation averaged less than 7 cm (3 in) per year. July and August are the warmest months with mean daily maxima over 19 °C (66 °F).\n",
      "Typically, the warmest day of the year (1971–2000) will achieve a temperature of 26.6 °C (80 °F), although in June 1976 the temperature reached 31.6 °C (89 °F), the site record. On average, 4.25 days of the year will report a maximum temperature of 25.1 °C (77 °F) or above. During the winter half of the year, the coldest night will typically fall to −4.1 °C (25 °F) although in January 1979 the temperature fell to −8.8 °C (16 °F). Typically, 18.6 nights of the year will register an air frost.\n",
      "The average temperature is 61.4 °F (16.3 °C), with the monthly daily average ranging from 39.2 °F (4.0 °C) in January to 83.0 °F (28.3 °C) in July. Extremes range from −17 °F (−27 °C) on February 12, 1899 to 113 °F (45 °C) on August 11, 1936 and August 3, 2012; the last sub-zero (°F) reading was −5 °F (−21 °C) on February 10, 2011. Temperatures reach 100 °F (38 °C) on 10.4 days of the year, 90 °F (32 °C) on nearly 70 days, and fail to rise above freezing on 8.3 days. The city receives about 35.9 inches (91.2 cm) of precipitation annually, of which 8.6 inches (21.8 cm) is snow.\n",
      "The climate of Saint Helena is tropical, marine and mild, tempered by the Benguela Current and trade winds that blow almost continuously. The climate varies noticeably across the island. Temperatures in Jamestown, on the north leeward shore, range between 21–28 °C (70–82 °F) in the summer (January to April) and 17–24 °C (63–75 °F) during the remainder of the year. The temperatures in the central areas are, on average, 5–6 °C (9.0–10.8 °F) lower. Jamestown also has a very low annual rainfall, while 750–1,000 mm (30–39 in) falls per year on the higher ground and the south coast, where it is also noticeably cloudier. There are weather recording stations in the Longwood and Blue Hill districts.\n",
      "There are no dedicated IPA symbols for degrees of aspiration and typically only two degrees are marked: unaspirated ⟨k⟩ and aspirated ⟨kʰ⟩. An old symbol for light aspiration was ⟨ʻ⟩, but this is now obsolete. The aspiration modifier letter may be doubled to indicate especially strong or long aspiration. Hence, the two degrees of aspiration in Korean stops are sometimes transcribed ⟨kʰ kʰʰ⟩ or ⟨kʻ⟩ and ⟨kʰ⟩, but they are usually transcribed [k] and [kʰ], with the details of voice-onset time given numerically.\n",
      "True aspirated voiced consonants, as opposed to murmured (breathy-voice) consonants such as the [bʱ], [dʱ], [ɡʱ] that are common in the languages of India, are extremely rare. They have been documented in Kelabit Taa, and the Kx'a languages. Reported aspirated voiced stops, affricates and clicks are [b͡pʰ, d͡tʰ, d͡tsʰ, d͡tʃʰ, ɡ͡kʰ, ɢ͡qʰ, ᶢʘʰ, ᶢǀʰ, ᶢǁʰ, ᶢǃʰ, ᶢǂʰ].\n",
      "Boston has a continental climate with some maritime influence, and using the −3 °C (27 °F) coldest month (January) isotherm, the city lies within the transition zone from a humid subtropical climate (Köppen Cfa) to a humid continental climate (Köppen Dfa), although the suburbs north and west of the city are significantly colder in winter and solidly fall under the latter categorization; the city lies at the transition between USDA plant hardiness zones 6b (most of the city) and 7a (Downtown, South Boston, and East Boston neighborhoods). Summers are typically warm to hot, rainy, and humid, while winters oscillate between periods of cold rain and snow, with cold temperatures. Spring and fall are usually mild, with varying conditions dependent on wind direction and jet stream positioning. Prevailing wind patterns that blow offshore minimize the influence of the Atlantic Ocean. The hottest month is July, with a mean temperature of 73.4 °F (23.0 °C). The coldest month is January, with a mean of 29.0 °F (−1.7 °C). Periods exceeding 90 °F (32 °C) in summer and below freezing in winter are not uncommon but rarely extended, with about 13 and 25 days per year seeing each, respectively. The most recent sub-0 °F (−18 °C) reading occurring on February 14, 2016 when the temperature dipped down to −9 °F (−23 °C), the coldest reading since 1957. In addition, several decades may pass between 100 °F (38 °C) readings, with the most recent such occurrence on July 22, 2011 when the temperature reached 103 °F (39 °C). The city's average window for freezing temperatures is November 9 through April 5.[c] Official temperature records have ranged from −18 °F (−28 °C) on February 9, 1934, up to 104 °F (40 °C) on July 4, 1911; the record cold daily maximum is 2 °F (−17 °C) on December 30, 1917, while, conversely, the record warm daily minimum is 83 °F (28 °C) on August 2, 1975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nanjing has a humid subtropical climate (Köppen Cfa) and is under the influence of the East Asian monsoon. The four seasons are distinct, with damp conditions seen throughout the year, very hot and muggy summers, cold, damp winters, and in between, spring and autumn are of reasonable length. Along with Chongqing and Wuhan, Nanjing is traditionally referred to as one of the \"Three Furnacelike Cities\" along the Yangtze River (长江流域三大火炉) for the perennially high temperatures in the summertime. However, the time from mid-June to the end of July is the plum blossom blooming season in which the meiyu (rainy season of East Asia; literally \"plum rain\") occurs, during which the city experiences a period of mild rain as well as dampness. Typhoons are uncommon but possible in the late stages of summer and early part of autumn. The annual mean temperature is around 15.46 °C (59.8 °F), with the monthly 24-hour average temperature ranging from 2.4 °C (36.3 °F) in January to 27.8 °C (82.0 °F) in July. Extremes since 1951 have ranged from −14.0 °C (7 °F) on 6 January 1955 to 40.7 °C (105 °F) on 22 August 1959. On average precipitation falls 115 days out of the year, and the average annual rainfall is 1,062 millimetres (42 in). With monthly percent possible sunshine ranging from 37 percent in March to 52 percent in August, the city receives 1,983 hours of bright sunshine annually.\n",
      "There are over three thousand islands along the rugged coastline of Zhejiang. The largest, Zhoushan Island, is Mainland China's third largest island, after Hainan and Chongming. There are also many bays, of which Hangzhou Bay is the largest.  Zhejiang has a humid subtropical climate with four distinct seasons. Spring starts in March and is rainy with changeable weather. Summer, from June to September is long, hot, rainy, and humid. Fall is generally dry, warm and sunny. Winters are short but cold except in the far south. Average annual temperature is around 15 to 19 °C (59 to 66 °F), average January temperature is around 2 to 8 °C (36 to 46 °F) and average July temperature is around 27 to 30 °C (81 to 86 °F). Annual precipitation is about 1,000 to 1,900 mm (39 to 75 in). There is plenty of rainfall in early summer, and by late summer Zhejiang is directly threatened by typhoons forming in the Pacific.\n",
      "The climate of New Delhi is a monsoon-influenced humid subtropical climate (Köppen Cwa) with high variation between summer and winter in terms of both temperature and rainfall. The temperature varies from 46 °C (115 °F) in summers to around 0 °C (32 °F) in winters. The area's version of a humid subtropical climate is noticeably different from many other cities with this climate classification in that it features long and very hot summers, relatively dry and mild winters, a monsoonal period, and dust storms. Summers are long, extending from early April to October, with the monsoon season occurring in the middle of the summer. Winter starts in November and peaks in January. The annual mean temperature is around 25 °C (77 °F); monthly daily mean temperatures range from approximately 14 to 34 °C (57 to 93 °F). New Delhi's highest temperature ever recorded is 49.1 °C (120.4 °F) while the lowest temperature ever recorded is −3.2 °C (26.2 °F). Those for Delhi metropolis stand at 49.9 °C (121.8 °F) and −3.2 °C (26.2 °F) respectively. The average annual rainfall is 784 millimetres (30.9 in), most of which is during the monsoons in July and August.\n",
      "Summers are typically warm and humid with a July daily average of 75.6 °F (24.2 °C). During this time, the city gets a sea breeze off the ocean that often makes daytime temperatures much cooler than inland areas, making Atlantic City a prime place for beating the summer heat from June through September. Average highs even just a few miles west of Atlantic City exceed 85 °F (29 °C) in July. Near the coast, temperatures reach or exceed 90 °F (32 °C) on an average of only 6.8 days a year, but this reaches 21 days at nearby Atlantic City Int'l.[a] Winters are cool, with January averaging 35.5 °F (2 °C). Spring and autumn are erratic, although they are usually mild with low humidity. The average window for freezing temperatures is November 20 to March 25, allowing a growing season of 239 days. Extreme temperatures range from −9 °F (−23 °C) on February 9, 1934 to 104 °F (40 °C) on August 7, 1918.[b]\n",
      "During the summer months, it is common for temperatures to reach over 90 °F (32 °C), with an average of 106.5 days per year, including a majority from June to September, with a high of 90 °F or above and 4.6 days at or over 100 °F (38 °C). However, humidity usually yields a higher heat index. Summer mornings average over 90 percent relative humidity. Winds are often light in the summer and offer little relief, except in the far southeastern outskirts near the Gulf coast and Galveston. To cope with the strong humidity and heat, people use air conditioning in nearly every vehicle and building. In 1980, Houston was described as the \"most air-conditioned place on earth\". Officially, the hottest temperature ever recorded in Houston is 109 °F (43 °C), which was reached both on September 4, 2000 and August 28, 2011.\n",
      "The Latin alphabet of the time still lacked the letters ⟨j⟩ and ⟨w⟩, and there was no ⟨v⟩ as distinct from ⟨u⟩; moreover native Old English spellings did not use ⟨k⟩, ⟨q⟩ or ⟨z⟩. The remaining 20 Latin letters were supplemented by four more: ⟨æ⟩ (æsc, modern ash) and ⟨ð⟩ (ðæt, now called eth or edh), which were modified Latin letters, and thorn ⟨þ⟩ and wynn ⟨ƿ⟩, which are borrowings from the futhorc. A few letter pairs were used as digraphs, representing a single sound. Also used was the Tironian note ⟨⁊⟩ (a character similar to the digit 7) for the conjunction and, and a thorn with a crossbar through the ascender for the pronoun þæt. Macrons over vowels were originally used not to mark long vowels (as in modern editions), but to indicate stress, or as abbreviations for a following m or n.\n",
      "Modern editions of Old English manuscripts generally introduce some additional conventions. The modern forms of Latin letters are used, including ⟨g⟩ in place of the insular G, ⟨s⟩ for long S, and others which may differ considerably from the insular script, notably ⟨e⟩, ⟨f⟩ and ⟨r⟩. Macrons are used to indicate long vowels, where usually no distinction was made between long and short vowels in the originals. (In some older editions an acute accent mark was used for consistency with Old Norse conventions.) Additionally, modern editions often distinguish between velar and palatal ⟨c⟩ and ⟨g⟩ by placing dots above the palatals: ⟨ċ⟩, ⟨ġ⟩. The letter wynn ⟨ƿ⟩ is usually replaced with ⟨w⟩, but æsc, eth and thorn are normally retained (except when eth is replaced by thorn).\n",
      "Antarctica, on average, is the coldest, driest, and windiest continent, and has the highest average elevation of all the continents. Antarctica is considered a desert, with annual precipitation of only 200 mm (8 in) along the coast and far less inland. The temperature in Antarctica has reached −89.2 °C (−128.6 °F), though the average for the third quarter (the coldest part of the year) is −63 °C (−81 °F). There are no permanent human residents, but anywhere from 1,000 to 5,000 people reside throughout the year at the research stations scattered across the continent. Organisms native to Antarctica include many types of algae, bacteria, fungi, plants, protista, and certain animals, such as mites, nematodes, penguins, seals and tardigrades. Vegetation, where it occurs, is tundra.\n",
      "Antarctica is the coldest of Earth's continents. The coldest natural temperature ever recorded on Earth was −89.2 °C (−128.6 °F) at the Soviet (now Russian) Vostok Station in Antarctica on 21 July 1983. For comparison, this is 10.7 °C (20 °F) colder than subliming dry ice at one atmosphere of partial pressure, but since CO2 only makes up 0.039% of air, temperatures of less than −150 °C (−238 °F) would be needed to produce dry ice snow in Antarctica. Antarctica is a frozen desert with little precipitation; the South Pole itself receives less than 10 cm (4 in) per year, on average. Temperatures reach a minimum of between −80 °C (−112 °F) and −89.2 °C (−128.6 °F) in the interior in winter and reach a maximum of between 5 °C (41 °F) and 15 °C (59 °F) near the coast in summer. Sunburn is often a health issue as the snow surface reflects almost all of the ultraviolet light falling on it. Given the latitude, long periods of constant darkness or constant sunlight create climates unfamiliar to human beings in much of the rest of the world.\n",
      "Its average annual temperature is 18.4 °C (65.1 °F). 22.8 °C (73.0 °F) during the day and 13.8 °C (56.8 °F) at night. In the coldest month – January, the maximum temperature typically during the day ranges from 13 to 21 °C (55 to 70 °F), the minimum temperature typically at night ranges from 4 to 12 °C (39 to 54 °F). In the warmest month – August, the maximum temperature during the day typically ranges from 28–34 °C (82–93 °F), about 23 °C (73 °F) at night. Generally, temperatures similar to those experienced in the northern part of Europe in summer last about 8 months, from April to November. March is transitional, the temperature often exceeds 20 °C (68 °F), with an average temperature of 19.0 °C (66 °F) during the day and 10.0 °C (50 °F) at night. December, January and February are the coldest months, with average temperatures around 17 °C (63 °F) during the day and 7 °C (45 °F) at night. Valencia has one of the mildest winters in Europe, owing to its southern location on the Mediterranean Sea and the Foehn phenomenon. The January average is comparable to temperatures expected for May and September in the major cities of northern Europe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present-day statutes from across the nation use the same words and phrases, requiring modern executions to take place within a wall or enclosure to exclude public view. Connecticut General Statute § 54–100 requires death sentences to be conducted in an \"enclosure\" which \"shall be so constructed as to exclude public view.\" Kentucky Revised Statute 431.220 and Missouri Revised Statute § 546.730 contain substantially identical language. New Mexico's former death penalty, since repealed, see N.M. Stat. § 31-14-12, required executions be conducted in a \"room or place enclosed from public view.\" Similarly, a dormant Massachusetts law, see Mass. Gen. Law ch. 279 § 60, required executions to take place \"within an enclosure or building.\" North Carolina General Statute § 15-188 requires death sentences to be executed \"within the walls\" of the penitentiary, as do Oklahoma Statute Title 22 § 1015 and Montana Code § 46-19-103. Ohio Revised Code § 2949.22 requires that \"[t]he enclosure shall exclude public view.\" Similarly, Tennessee Code § 40-23-116 requires \"an enclosure\" for \"strict seclusion and privacy.\" United States Code Title 18 § 3596 and the Code of Federal Regulations 28 CFR 26.4 limit the witnesses permitted at federal executions.\n",
      "Autumn, winter, and early spring are frequently characterized by rain. Winters are cool and wet with December, the coolest month, averaging 40.6 °F (4.8 °C), with 28 annual days with lows that reach the freezing mark, and 2.0 days where the temperature stays at or below freezing all day; the temperature rarely lowers to 20 °F (−7 °C). Summers are sunny, dry and warm, with August, the warmest month, averaging 66.1 °F (18.9 °C), and with temperatures reaching 90 °F (32 °C) on 3.1 days per year, although 2011 is the most recent year to not reach 90 °F. The hottest officially recorded temperature was 103 °F (39 °C) on July 29, 2009; the coldest recorded temperature was 0 °F (−18 °C) on January 31, 1950; the record cold daily maximum is 16 °F (−9 °C) on January 14, 1950, while, conversely, the record warm daily minimum is 71 °F (22 °C) the day the official record high was set. The average window for freezing temperatures is November 16 thru March 10, allowing a growing season of 250 days.\n",
      "The Umayyad Caliphate (Arabic: الخلافة الأموية‎, trans. Al-Khilāfat al-ʾumawiyya) was the second of the four major Islamic caliphates established after the death of Muhammad. This caliphate was centered on the Umayyad dynasty (Arabic: الأمويون‎, al-ʾUmawiyyūn, or بنو أمية, Banū ʾUmayya, \"Sons of Umayya\"), hailing from Mecca. The Umayyad family had first come to power under the third caliph, Uthman ibn Affan (r. 644–656), but the Umayyad regime was founded by Muawiya ibn Abi Sufyan, long-time governor of Syria, after the end of the First Muslim Civil War in 661 CE/41 AH. Syria remained the Umayyads' main power base thereafter, and Damascus was their capital. The Umayyads continued the Muslim conquests, incorporating the Caucasus, Transoxiana, Sindh, the Maghreb and the Iberian Peninsula (Al-Andalus) into the Muslim world. At its greatest extent, the Umayyad Caliphate covered 15 million km2 (5.79 million square miles), making it the largest empire (in terms of area - not in terms of population) the world had yet seen, and the fifth largest ever to exist.\n",
      "The term Hokkien (福建; hɔk˥˥kɪɛn˨˩) is itself a term not used in Chinese to refer to the dialect, as it simply means Fujian province. In Chinese linguistics, these dialects are known by their classification under the Quanzhang Division (Chinese: 泉漳片; pinyin: Quánzhāng piàn) of Min Nan, which comes from the first characters of the two main Hokkien urban centers Quanzhou and Zhangzhou. The variety is also known by other terms such as the more general Min Nan (traditional Chinese: 閩南語, 閩南話; simplified Chinese: 闽南语, 闽南话; pinyin: Mǐnnányǔ, Mǐnnánhuà; Pe̍h-ōe-jī: Bân-lâm-gí,Bân-lâm-oē) or Southern Min, and Fulaohua (traditional Chinese: 福佬話; simplified Chinese: 福佬话; pinyin: Fúlǎohuà; Pe̍h-ōe-jī: Hō-ló-oē). The term Hokkien (Chinese: 福建話; Pe̍h-ōe-jī: hok-kiàn oē;Tâi-lô:Hok-kiàn-uē), on the other hand, is used commonly in South East Asia to refer to Min-nan dialects.\n",
      "While most Hokkien morphemes have standard designated characters, they are not always etymological or phono-semantic. Similar-sounding, similar-meaning or rare characters are commonly borrowed or substituted to represent a particular morpheme. Examples include \"beautiful\" (美 bí is the literary form), whose vernacular morpheme suí is represented by characters like 媠 (an obsolete character), 婎 (a vernacular reading of this character) and even 水 (transliteration of the sound suí), or \"tall\" (高 ko is the literary form), whose morpheme kôan is 懸. Common grammatical particles are not exempt; the negation particle m̄ (not) is variously represented by 毋, 呣 or 唔, among others. In other cases, characters are invented to represent a particular morpheme (a common example is the character 𪜶 in, which represents the personal pronoun \"they\"). In addition, some characters have multiple and unrelated pronunciations, adapted to represent Hokkien words. For example, the Hokkien word bah (\"meat\") has been reduced to the character 肉, which has etymologically unrelated colloquial and literary readings (he̍k and jio̍k, respectively). Another case is the word 'to eat,' chia̍h, which is often transcribed in Taiwanese newspapers and media as 呷 (a Mandarin transliteration, xiā, to approximate the Hokkien term), even though its recommended character in dictionaries is 食.\n",
      "In China, the war is officially called the \"War to Resist U.S. Aggression and Aid Korea\" (simplified Chinese: 抗美援朝战争; traditional Chinese: 抗美援朝戰爭; pinyin: Kàngměiyuáncháo zhànzhēng), although the term \"Chaoxian (Korean) War\" (simplified Chinese: 朝鲜战争; traditional Chinese: 朝鮮戰爭; pinyin: Cháoxiǎn zhànzhēng) is also used in unofficial contexts, along with the term \"Korean Conflict\" (simplified Chinese: 韩战; traditional Chinese: 韓戰; pinyin: Hán Zhàn) more commonly used in regions such as Hong Kong and Macau.\n",
      "The climate of Florida is tempered somewhat by the fact that no part of the state is distant from the ocean. North of Lake Okeechobee, the prevalent climate is humid subtropical (Köppen: Cfa), while areas south of the lake (including the Florida Keys) have a true tropical climate (Köppen: Aw). Mean high temperatures for late July are primarily in the low 90s Fahrenheit (32–34 °C). Mean low temperatures for early to mid January range from the low 40s Fahrenheit (4–7 °C) in northern Florida to above 60 °F (16 °C) from Miami on southward. With an average daily temperature of 70.7 °F (21.5 °C), it is the warmest state in the country.\n",
      "Most of the Korean Presbyterian denominations share the same name in Korean, 대한예수교장로회 (literally means the Presbyterian Church of Korea or PCK), tracing its roots to the United Presbyterian Assembly before its long history of disputes and schisms. The Presbyterian schism began with the controversy in relation to the Japanese shrine worship enforced during the Japanese colonial period and the establishment of a minor division (Koryu-pa, 고려파, later The Koshin Presbyterian Church in Korea, Koshin 고신) in 1952. And in 1953 the second schism happened when the theological orientation of the Chosun Seminary (later Hanshin University) founded in 1947 could not be tolerated in the PCK and another minor group (The Presbyterian Church in the Republic of Korea, Kijang, 기장) was separated. The last major schism had to do with the issue of whether the PCK should join the WCC. The controversy divided the PCK into two denominations, The Presbyterian Church of Korea (Tonghap, 통합) and The General Assembly of Presbyterian Church in Korea (Hapdong, 합동) in 1959. All major seminaries associated with each denomination claim heritage from the Pyung Yang Theological Seminary, therefore, not only Presbyterian University and Theological Seminary and Chongsin University which are related to PCK but also Hanshin University of PROK all celebrated the 100th class in 2007, 100 years from the first graduates of Pyung Yang Theological Seminary.\n",
      "Summers are generally warm and sometimes hot. London's average July high is 24 °C (75.2 °F). On average London will see 31 days above 25 °C (77.0 °F) each year, and 4.2 days above 30.0 °C (86.0 °F) every year. During the 2003 European heat wave there were 14 consecutive days above 30 °C (86.0 °F) and 2 consecutive days where temperatures reached 38 °C (100.4 °F), leading to hundreds of heat related deaths. Winters are generally cool and damp with little temperature variation. Snowfall does occur from time to time, and can cause travel disruption when this happens. Spring and autumn are mixed seasons and can be pleasant. As a large city, London has a considerable urban heat island effect, making the centre of London at times 5 °C (9 °F) warmer than the suburbs and outskirts. The effect of this can be seen below when comparing London Heathrow, 15 miles west of London, with the London Weather Centre, in the city centre.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Along with the rest of South West England, Somerset has a temperate climate which is generally wetter and milder than the rest of the country. The annual mean temperature is approximately 10 °C (50.0 °F). Seasonal temperature variation is less extreme than most of the United Kingdom because of the adjacent sea temperatures. The summer months of July and August are the warmest with mean daily maxima of approximately 21 °C (69.8 °F). In winter mean minimum temperatures of 1 °C (33.8 °F) or 2 °C (35.6 °F) are common. In the summer the Azores high pressure affects the south-west of England, but convective cloud sometimes forms inland, reducing the number of hours of sunshine. Annual sunshine rates are slightly less than the regional average of 1,600 hours. In December 1998 there were 20 days without sun recorded at Yeovilton. Most the rainfall in the south-west is caused by Atlantic depressions or by convection. Most of the rainfall in autumn and winter is caused by the Atlantic depressions, which is when they are most active. In summer, a large proportion of the rainfall is caused by sun heating the ground leading to convection and to showers and thunderstorms. Average rainfall is around 700 mm (28 in). About 8–15 days of snowfall is typical. November to March have the highest mean wind speeds, and June to August the lightest winds. The predominant wind direction is from the south-west.\n",
      "Ann Arbor has a typically Midwestern humid continental climate (Köppen Dfa), which is influenced by the Great Lakes. There are four distinct seasons: winters are cold with moderate to heavy snowfall, while summers are very warm and humid, and spring and autumn are short but mild. The area experiences lake effect weather, primarily in the form of increased cloudiness during late fall and early winter. The monthly daily average temperature in July is 72.6 °F (22.6 °C), while the same figure for January is 24.5 °F (−4.2 °C). Temperatures reach or exceed 90 °F (32 °C) on 10 days, and drop to or below 0 °F (−18 °C) on 4.6 nights. Precipitation tends to be the heaviest during the summer months, but most frequent during winter. Snowfall, which normally occurs from November to April but occasionally starts in October, averages 58 inches (147 cm) per season. The lowest recorded temperature was −23 °F (−31 °C) on 11 February 1885 and the highest recorded temperature was 105 °F (41 °C) on 24 July 1934.\n",
      "Like much of the southeastern United States, Raleigh has a humid subtropical climate (Köppen Cfa), with four distinct seasons. Winters are short and generally cool, with a January daily average of 41.0 °F (5.0 °C). On average, there are 69 nights per year that drop to or below freezing, and only 2.7 days that fail to rise above freezing. April is the driest month, with an average of 2.91 inches (73.9 mm) of precipitation. Precipitation is well distributed around the year, with a slight maximum between July and September; on average, July is the wettest month, owing to generally frequent, sometimes heavy, showers and thunderstorms. Summers are hot and humid, with a daily average in July of 80.0 °F (26.7 °C). There are 48 days per year with highs at or above 90 °F (32 °C). Autumn is similar to spring overall but has fewer days of rainfall. Extremes in temperature have ranged from −9 °F (−23 °C) on January 21, 1985 up to 105 °F (41 °C), most recently on July 8, 2012.\n",
      "Examples are 河 hé \"river\", 湖 hú \"lake\", 流 liú \"stream\", 沖 chōng \"riptide\" (or \"flush\"), 滑 huá \"slippery\". All these characters have on the left a radical of three short strokes (氵), which is a reduced form of the character 水 shuǐ meaning \"water\", indicating that the character has a semantic connection with water. The right-hand side in each case is a phonetic indicator. For example, in the case of 沖 chōng (Old Chinese *ɡ-ljuŋ), the phonetic indicator is 中 zhōng (Old Chinese *k-ljuŋ), which by itself means \"middle\". In this case it can be seen that the pronunciation of the character is slightly different from that of its phonetic indicator; the process of historical phonetic change means that the composition of such characters can sometimes seem arbitrary today.\n",
      "Contrary to the popular belief of there being only one script per period, there were in fact multiple scripts in use during the Han period. Although mature clerical script, also called 八分 (bāfēn) script, was dominant at that time, an early type of cursive script was also in use by the Han by at least as early as 24 BC (during the very late Western Han period),[b] incorporating cursive forms popular at the time, well as many elements from the vulgar writing of the Warring State of Qin. By around the time of the Eastern Jin dynasty, this Han cursive became known as 章草 zhāngcǎo (also known as 隶草 / 隸草 lìcǎo today), or in English sometimes clerical cursive, ancient cursive, or draft cursive. Some believe that the name, based on 章 zhāng meaning \"orderly\", arose because the script was a more orderly form of cursive than the modern form, which emerged during the Eastern Jin dynasty and is still in use today, called 今草 jīncǎo or \"modern cursive\".\n",
      "One of the most complex characters found in modern Chinese dictionaries[g] is 齉 (U+9F49) (nàng,  listen (help·info), pictured below, middle image), meaning \"snuffle\" (that is, a pronunciation marred by a blocked nose), with \"just\" thirty-six strokes. However, this is not in common use. The most complex character that can be input using the Microsoft New Phonetic IME 2002a for traditional Chinese is 龘 (dá, \"the appearance of a dragon flying\"). It is composed of the dragon radical represented three times, for a total of 16 × 3 = 48 strokes. Among the most complex characters in modern dictionaries and also in frequent modern use are 籲 (yù, \"to implore\"), with 32 strokes; 鬱 (yù, \"luxuriant, lush; gloomy\"), with 29 strokes, as in 憂鬱 (yōuyù, \"depressed\"); 豔 (yàn, \"colorful\"), with 28 strokes; and 釁 (xìn, \"quarrel\"), with 25 strokes, as in 挑釁 (tiǎoxìn, \"to pick a fight\"). Also in occasional modern use is 鱻 (xiān \"fresh\"; variant of 鮮 xiān) with 33 strokes.\n",
      "Modern examples particularly include Chinese characters for SI units. In Chinese these units are disyllabic and standardly written with two characters, as 厘米 límǐ \"centimeter\" (厘 centi-, 米 meter) or 千瓦 qiānwǎ \"kilowatt\". However, in the 19th century these were often written via compound characters, pronounced disyllabically, such as 瓩 for 千瓦 or 糎 for 厘米 – some of these characters were also used in Japan, where they were pronounced with borrowed European readings instead. These have now fallen out of general use, but are occasionally seen. Less systematic examples include 圕 túshūguǎn \"library\", a contraction of 圖書館, A four-morpheme word, 社会主义 shèhuì zhǔyì \"socialism\", is commonly written with a single character formed by combining the last character, 义, with the radical of the first, 社, yielding roughly 礻义.\n",
      "A commonly seen example is the double happiness symbol 囍, formed as a ligature of 喜喜 and referred to by its disyllabic name (simplified Chinese: 双喜; traditional Chinese: 雙喜; pinyin: shuāngxǐ). In handwriting, numbers are very frequently squeezed into one space or combined – common ligatures include 廿 niàn, \"twenty\", normally read as 二十 èrshí, 卅 sà, \"thirty\", normally read as 三十 sānshí, and 卌 xì \"forty\", normally read as 四十 \"sìshí\". In some cases counters are also merged into one character, such as 七十人 qīshí rén \"seventy people\". Another common abbreviation is 门 with a \"T\" written inside it, for 問題, 问题, wèntí (\"question; problem\"), where the \"T\" is from pinyin for the second syllable tí 题. Since polysyllabic characters are often non-standard, they are often excluded incharcter dictionaries.\n",
      "In the years after World War II, the Japanese government also instituted a series of orthographic reforms. Some characters were given simplified forms called shinjitai 新字体 (lit. \"new character forms\", the older forms were then labelled the kyūjitai 旧字体, lit. \"old character forms\"). The number of characters in common use was restricted, and formal lists of characters to be learned during each grade of school were established, first the 1850-character tōyō kanji 当用漢字 list in 1945, the 1945-character jōyō kanji 常用漢字 list in 1981, and a 2136-character reformed version of the jōyō kanji in 2010. Many variant forms of characters and obscure alternatives for common characters were officially discouraged. This was done with the goal of facilitating learning for children and simplifying kanji use in literature and periodicals. These are simply guidelines, hence many characters outside these standards are still widely known and commonly used, especially those used for personal and place names (for the latter, see jinmeiyō kanji),[citation needed] as well as for some common words such as \"dragon\" (Japanese kana: たつ, Rōmaji: tatsu) in which both the shinjitai 竜 and the kyūjitai 龍 forms of the kanji are both acceptable and widely known amongst native Japanese speakers.\n",
      "The majority of simplified characters are drawn from conventional abbreviated forms, or ancient standard forms. For example, the orthodox character 來 lái (\"come\") was written with the structure 来 in the clerical script (隶书 / 隸書, lìshū) of the Han dynasty. This clerical form uses one fewer stroke, and was thus adopted as a simplified form. The character 雲 yún (\"cloud\") was written with the structure 云 in the oracle bone script of the Shang dynasty, and had remained in use later as a phonetic loan in the meaning of \"to say\" while the 雨 radical was added to differentiate meanings. The simplified form adopts the original structure.\n",
      "When learning how to write hanja, students are taught to memorize the native Korean pronunciation for the hanja's meaning and the Sino-Korean pronunciations (the pronunciation based on the Chinese pronunciation of the characters) for each hanja respectively so that students know what the syllable and meaning is for a particular hanja. For example, the name for the hanja 水 is 물 수 (mul-su) in which 물 (mul) is the native Korean pronunciation for \"water\", while 수 (su) is the Sino-Korean pronunciation of the character. The naming of hanja is similar to if \"water\" were named \"water-aqua\", \"horse-equus\", or \"gold-aurum\" based on a hybridization of both the English and the Latin names. Other examples include 사람 인 (saram-in) for 人 \"person/people\", 큰 대 (keun-dae) for 大 \"big/large//great\", 작을 소 (jakeul-so) for 小 \"small/little\", 아래 하 (arae-ha) for 下 \"underneath/below/low\", 아비 부 (abi-bu) for 父 \"father\", and 나라이름 한 (naraimreum-han) for 韓 \"Han/Korea\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The climate of the coastal plain is influenced by the Atlantic Ocean, which keeps conditions mild in winter and moderate, although humid, in summer. The highest coastal, daytime temperature averages less than 89 °F (32 °C) during summer months. The coast has mild temperatures in winter, with daytime highs rarely below 40 °F (4 °C). The average daytime temperature in the coastal plain is usually in the mid-50s °F (11–14 °C) in winter. Temperatures in the coastal plain only occasionally drop below the freezing point at night. The coastal plain averages only around 1 inch (2.5 cm) of snow or ice annually, and in many years, there may be no snow or ice at all.\n",
      "The Appalachian Mountains are the coolest area of the state, with temperatures averaging in the low 40s and upper 30s °F (6–3 °C) for highs in the winter and falling into the low 20s °F (−5 °C) or lower on winter nights. Relatively cool summers have temperatures rarely rising above 80 °F (27 °C). Average snowfall in many areas exceeds 30 in (76 cm) per year, and can be heavy at the higher elevations; for example, during the Blizzard of 1993 more than 60 in (152 cm) of snow fell on Mount Mitchell over a period of three days. Mount Mitchell has received snow in every month of the year.\n",
      "Miami has a tropical monsoon climate (Köppen climate classification Am) with hot and humid summers and short, warm winters, with a marked drier season in the winter. Its sea-level elevation, coastal location, position just above the Tropic of Cancer, and proximity to the Gulf Stream shapes its climate. With January averaging 67.2 °F (19.6 °C), winter features mild to warm temperatures; cool air usually settles after the passage of a cold front, which produces much of the little amount of rainfall during the season. Lows occasionally fall below 50 °F (10 °C), but very rarely below 35 °F (2 °C). Highs generally range between 70–77 °F (21–25 °C).\n",
      "Being located on the Atlantic coastline, Galicia has a very mild climate for the latitude and the marine influence affects most of the province to various degrees. In comparison to similar latitudes on the other side of the Atlantic, winters are exceptionally mild, with consistently heavy rainfall. Snow is rare due to temperatures rarely dropping below freezing. The warmest coastal station of Pontevedra has a yearly mean temperature of 14.8 °C (58.6 °F). Ourense located somewhat inland is only slightly warmer with 14.9 °C (58.8 °F). Due to its exposed north-westerly location, the climate is still very cool by Spanish standards. In coastal areas summers are temperered, averaging around 25 °C (77 °F) in Vigo. Temperatures are further cooler in A Coruña, with a subdued 22.8 °C (73.0 °F) normal. Temperatures do however soar in inland areas such as Ourense, where days above 30 °C (86 °F) are very regular.\n",
      "Thai alphabet support has been criticized for its ordering of Thai characters. The vowels เ, แ, โ, ใ, ไ that are written to the left of the preceding consonant are in visual order instead of phonetic order, unlike the Unicode representations of other Indic scripts. This complication is due to Unicode inheriting the Thai Industrial Standard 620, which worked in the same way, and was the way in which Thai had always been written on keyboards. This ordering problem complicates the Unicode collation process slightly, requiring table lookups to reorder Thai characters for collation. Even if Unicode had adopted encoding according to spoken order, it would still be problematic to collate words in dictionary order. E.g., the word แสดง  [sa dɛːŋ] \"perform\" starts with a consonant cluster \"สด\" (with an inherent vowel for the consonant \"ส\"), the vowel แ-, in spoken order would come after the ด, but in a dictionary, the word is collated as it is written, with the vowel following the ส.\n",
      "Detroit and the rest of southeastern Michigan have a humid continental climate (Köppen Dfa) which is influenced by the Great Lakes; the city and close-in suburbs are part of USDA Hardiness zone 6b, with farther-out northern and western suburbs generally falling in zone 6a. Winters are cold, with moderate snowfall and temperatures not rising above freezing on an average 44 days annually, while dropping to or below 0 °F (−18 °C) on an average 4.4 days a year; summers are warm to hot with temperatures exceeding 90 °F (32 °C) on 12 days. The warm season runs from May to September. The monthly daily mean temperature ranges from 25.6 °F (−3.6 °C) in January to 73.6 °F (23.1 °C) in July. Official temperature extremes range from 105 °F (41 °C) on July 24, 1934 down to −21 °F (−29 °C) on January 21, 1984; the record low maximum is −4 °F (−20 °C) on January 19, 1994, while, conversely the record high minimum is 80 °F (27 °C) on August 1, 2006, the most recent of five occurrences. A decade or two may pass between readings of 100 °F (38 °C) or higher, which last occurred July 17, 2012. The average window for freezing temperatures is October 20 thru April 22, allowing a growing season of 180 days.\n",
      "The sky is usually clear above the desert and the sunshine duration is extremely high everywhere in the Sahara. Most of the desert enjoys more than 3,600 h of bright sunshine annually or over 82% of the time and a wide area in the eastern part experiences in excess of 4,000 h of bright sunshine a year or over 91% of the time, and the highest values are very close to the theoretical maximum value. A value of 4,300 h or 98% of the time would be recorded in Upper Egypt (Aswan, Luxor) and in the Nubian Desert (Wadi Halfa). The annual average direct solar irradiation is around 2,800 kWh/(m2 year) in the Great Desert. The Sahara has a huge potential for solar energy production. The constantly high position of the sun, the extremely low relative humidity, the lack of vegetation and rainfall make the Great Desert the hottest continuously large area worldwide and certainly the hottest place on Earth during summertime in some spots. The average high temperature exceeds 38 °C (100.4 °F) - 40 °C (104 °F) during the hottest month nearly everywhere in the desert except at very high mountainous areas. The highest officially recorded average high temperature was 47 °C (116.6 °F) in a remote desert town in the Algerian Desert called Bou Bernous with an elevation of 378 meters above sea level. It's the world's highest recorded average high temperature and only Death Valley, California rivals it. Other hot spots in Algeria such as Adrar, Timimoun, In Salah, Ouallene, Aoulef, Reggane with an elevation between 200 and 400 meters above sea level get slightly lower summer average highs around 46 °C (114.8 °F) during the hottest months of the year. Salah, well known in Algeria for its extreme heat, has an average high temperature of 43.8 °C (110.8 °F), 46.4 °C (115.5 °F), 45.5 (113.9 °F). Furthermore, 41.9 °C (107.4 °F) in June, July, August and September. In fact, there are even hotter spots in the Sahara, but they are located in extremely remote areas, especially in the Azalai, lying in northern Mali. The major part of the desert experiences around 3 – 5 months when the average high strictly exceeds 40 °C (104 °F). The southern central part of the desert experiences up to 6 – 7 months when the average high temperature strictly exceeds 40 °C (104 °F) which shows the constancy and the length of the really hot season in the Sahara. Some examples of this are Bilma, Niger and Faya-Largeau, Chad. The annual average daily temperature exceeds 20 °C (68 °F) everywhere and can approach 30 °C (86 °F) in the hottest regions year-round. However, most of the desert has a value in excess of 25 °C (77 °F). The sand and ground temperatures are even more extreme. During daytime, the sand temperature is extremely high as it can easily reach 80 °C (176 °F) or more. A sand temperature of 83.5 °C (182.3 °F) has been recorded in Port Sudan. Ground temperatures of 72 °C (161.6 °F) have been recorded in the Adrar of Mauritania and a value of 75 °C (167 °F) has been measured in Borkou, northern Chad. Due to lack of cloud cover and very low humidity, the desert usually features high diurnal temperature variations between days and nights. However, it's a myth that the nights are cold after extremely hot days in the Sahara. The average diurnal temperature range is typically between 13 °C (55.4 °F) and 20 °C (68 °F). The lowest values are found along the coastal regions due to high humidity and are often even lower than 10 °C (50 °F), while the highest values are found in inland desert areas where the humidity is the lowest, mainly in the southern Sahara. Still, it's true that winter nights can be cold as it can drop to the freezing point and even below, especially in high-elevation areas.\n",
      "The best-known medieval Chinese name for Tibet is Tubo (Chinese: 吐蕃 also written as 土蕃 or 土番; pinyin: Tǔbō or Tǔfān). This name first appears in Chinese characters as 土番 in the 7th century (Li Tai) and as 吐蕃 in the 10th-century (Old Book of Tang describing 608–609 emissaries from Tibetan King Namri Songtsen to Emperor Yang of Sui). In the Middle Chinese spoken during that period, as reconstructed by William H. Baxter, 土番 was pronounced thux-phjon and 吐蕃 was pronounced thux-pjon (with the x representing tone).\n",
      "Other pre-modern Chinese names for Tibet include Wusiguo (Chinese: 烏斯國; pinyin: Wūsīguó; cf. Tibetan dbus, Ü, [wyʔ˨˧˨]), Wusizang (Chinese: 烏斯藏; pinyin: wūsīzàng, cf. Tibetan dbus-gtsang, Ü-Tsang), Tubote (Chinese: 圖伯特; pinyin: Túbótè), and Tanggute (Chinese: 唐古忒; pinyin: Tánggǔtè, cf. Tangut). American Tibetologist Elliot Sperling has argued in favor of a recent tendency by some authors writing in Chinese to revive the term Tubote (simplified Chinese: 图伯特; traditional Chinese: 圖伯特; pinyin: Túbótè) for modern use in place of Xizang, on the grounds that Tubote more clearly includes the entire Tibetan plateau rather than simply the Tibet Autonomous Region.[citation needed]\n",
      "All of the state frequently experiences temperatures above 100 °F (38 °C) or below 0 °F (−18 °C), though below-zero temperatures are rare in south-central and southeastern Oklahoma. Snowfall ranges from an average of less than 4 inches (10 cm) in the south to just over 20 inches (51 cm) on the border of Colorado in the panhandle. The state is home to the Storm Prediction Center, the National Severe Storms Laboratory, and the Warning Decision Training Branch, all part of the National Weather Service and located in Norman. Oklahoma's highest recorded temperature of 120 °F (49 °C) was recorded at Tipton on June 27, 1994 and the lowest recorded temperature of −31 °F (−35 °C) was recorded at Nowata on February 10, 2011.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estonia is situated in the northern part of the temperate climate zone and in the transition zone between maritime and continental climate. Estonia has four seasons of near-equal length. Average temperatures range from 16.3 °C (61.3 °F) on the Baltic islands to 18.1 °C (64.6 °F) inland in July, the warmest month, and from −3.5 °C (25.7 °F) on the Baltic islands to −7.6 °C (18.3 °F) inland in February, the coldest month. The average annual temperature in Estonia is 5.2 °C (41.4 °F). The average precipitation in 1961–1990 ranged from 535 to 727 mm (21.1 to 28.6 in) per year.\n",
      "Paris has a typical Western European oceanic climate (Köppen climate classification: Cfb ) which is affected by the North Atlantic Current. The overall climate throughout the year is mild and moderately wet. Summer days are usually warm and pleasant with average temperatures hovering between 15 and 25 °C (59 and 77 °F), and a fair amount of sunshine. Each year, however, there are a few days where the temperature rises above 32 °C (90 °F). Some years have even witnessed long periods of harsh summer weather, such as the heat wave of 2003 when temperatures exceeded 30 °C (86 °F) for weeks, surged up to 40 °C (104 °F) on some days and seldom cooled down at night. More recently, the average temperature for July 2011 was 17.6 °C (63.7 °F), with an average minimum temperature of 12.9 °C (55.2 °F) and an average maximum temperature of 23.7 °C (74.7 °F).\n",
      "Several instances of popular etymology are attested from ancient authors. Thus, the Greeks most often associated Apollo's name with the Greek verb ἀπόλλυμι (apollymi), \"to destroy\". Plato in Cratylus connects the name with ἀπόλυσις (apolysis), \"redemption\", with ἀπόλουσις (apolousis), \"purification\", and with ἁπλοῦν ([h]aploun), \"simple\", in particular in reference to the Thessalian form of the name, Ἄπλουν, and finally with Ἀειβάλλων (aeiballon), \"ever-shooting\". Hesychius connects the name Apollo with the Doric ἀπέλλα (apella), which means \"assembly\", so that Apollo would be the god of political life, and he also gives the explanation σηκός (sekos), \"fold\", in which case Apollo would be the god of flocks and herds. In the Ancient Macedonian language πέλλα (pella) means \"stone,\" and some toponyms may be derived from this word: Πέλλα (Pella, the capital of Ancient Macedonia) and Πελλήνη (Pellēnē/Pallene).\n",
      "As a protector and founder, Apollo had the epithets Alexicacus (/əˌlɛksᵻˈkeɪkəs/ ə-LEK-si-KAY-kəs; Ἀλεξίκακος, Alexikakos, literally \"warding off evil\"), Apotropaeus (/əˌpɒtrəˈpiːəs/ ə-POT-rə-PEE-əs; Ἀποτρόπαιος, Apotropaios, from ἀποτρέπειν, \"to avert\"), and Epicurius (/ˌɛpᵻˈkjʊriəs/ EP-i-KEWR-ee-əs; Ἐπικούριος, Epikourios, from ἐπικουρέειν, \"to aid\"), and Archegetes (/ɑːrˈkɛdʒətiːz/ ar-KEJ-ə-teez; Ἀρχηγέτης, Arkhēgetēs, literally \"founder\"), Clarius (/ˈklæriəs/ KLARR-ee-əs; Κλάριος, Klārios, from Doric κλάρος, \"allotted lot\"), and Genetor (/ˈdʒɛnᵻtər/ JEN-i-tər; Γενέτωρ, Genetōr, literally \"ancestor\"). To the Romans, he was known in this capacity as Averruncus (/ˌævəˈrʌŋkəs/ AV-ər-RUNG-kəs; from Latin āverruncare, \"to avert\"). He was also called Agyieus (/əˈdʒaɪ.ᵻjuːs/ ə-GWEE-ews; Ἀγυιεύς, Aguīeus, from ἄγυια, \"street\") for his role in protecting roads and homes; and Nomius (/ˈnoʊmiəs/ NOH-mee-əs; Νόμιος, Nomios, literally \"pastoral\") and Nymphegetes (/nɪmˈfɛdʒᵻtiːz/ nim-FEJ-i-teez; Νυμφηγέτης, Numphēgetēs, from Νύμφη, \"Nymph\", and ἡγέτης, \"leader\") for his role as a protector of shepherds and pastoral life.\n",
      "As a god of archery, Apollo was known as Aphetor (/əˈfiːtər/ ə-FEE-tər; Ἀφήτωρ, Aphētōr, from ἀφίημι, \"to let loose\") or Aphetorus (/əˈfɛtərəs/ ə-FET-ər-əs; Ἀφητόρος, Aphētoros, of the same origin), Argyrotoxus (/ˌɑːrdʒᵻrəˈtɒksəs/ AR-ji-rə-TOK-səs; Ἀργυρότοξος, Argyrotoxos, literally \"with silver bow\"), Hecaërgus (/ˌhɛkiˈɜːrɡəs/ HEK-ee-UR-gəs; Ἑκάεργος, Hekaergos, literally \"far-shooting\"), and Hecebolus (/hᵻˈsɛbələs/ hi-SEB-ə-ləs; Ἑκηβόλος, Hekēbolos, literally \"far-shooting\"). The Romans referred to Apollo as Articenens (/ɑːrˈtɪsᵻnənz/ ar-TISS-i-nənz; \"bow-carrying\"). Apollo was called Ismenius (/ɪzˈmiːniəs/ iz-MEE-nee-əs; Ἰσμηνιός, Ismēnios, literally \"of Ismenus\") after Ismenus, the son of Amphion and Niobe, whom he struck with an arrow.\n",
      "In 2012, Fortune ranked IBM the second largest U.S. firm in terms of number of employees (435,000 worldwide), the fourth largest in terms of market capitalization, the ninth most profitable, and the nineteenth largest firm in terms of revenue. Globally, the company was ranked the 31st largest in terms of revenue by Forbes for 2011. Other rankings for 2011/2012 include №1 company for leaders (Fortune), №1 green company in the United States (Newsweek), №2 best global brand (Interbrand), №2 most respected company (Barron's), №5 most admired company (Fortune), and №18 most innovative company (Fast Company).\n",
      "Palermo experiences a hot-summer Mediterranean climate (Köppen climate classification: Csa). Winters are cool and wet, while summers are hot and dry. Temperatures in autumn and spring are usually mild. Palermo is one of the warmest cities in Europe (mainly due to its warm nights), with an average annual air temperature of 18.5 °C (65.3 °F). It receives approximately 2,530 hours of sunshine per year. Snow is usually a rare occurrence, but it does occur occasionally if there is a cold front, as the Apennines are too distant to protect the island from cold winds blowing from the Balkans, and the mountains surrounding the city facilite the formation of snow accumulation in Palermo, especially at night. Between the 1940s and the 2000s there have been eleven times when considerable snowfall has occurred: In 1949, in 1956, when the minimum temperature went down to 0 °C (32 °F) and the city was blanketed by several centimeters of snow. Snow also occurred in 1999, 2009 and 2015. The average annual temperature of the sea is above 19 °C (66 °F); from 14 °C (57 °F) in February to 26 °C (79 °F) in August. In the period from May to November, the average sea temperature exceeds 18 °C (64 °F) and in the period from June to October, the average sea temperature exceeds 21 °C (70 °F).\n",
      "The word Ottoman is a historical anglicisation of the name of Osman I, the founder of the Empire and of the ruling House of Osman (also known as the Ottoman dynasty). Osman's name in turn was derived from the Persian form of the name ʿUthmān عثمان of ultimately Arabic origin. In Ottoman Turkish, the empire was referred to as Devlet-i ʿAliyye-yi ʿOsmâniyye (دَوْلَتِ عَلِيّهٔ عُثمَانِیّه), (literally \"The Supreme State of the Ottomans\") or alternatively Osmanlı Devleti (عثمانلى دولتى).[dn 5] In Modern Turkish, it is known as Osmanlı İmparatorluğu (\"Ottoman Empire\") or Osmanlı Devleti (\"The Ottoman State\").\n",
      "The January daily average is 33.0 °F (0.6 °C), though, in a normal winter, the temperature frequently rises to 50 °F (10 °C) during thaws and dips to 10 °F (−12 °C) for 2 or 3 nights. July averages 78.1 °F (25.6 °C), although heat waves accompanied by high humidity and heat indices are frequent; highs reach or exceed 90 °F (32 °C) on 27 days of the year. The average window for freezing temperatures is November 6 thru April 2, allowing a growing season of 217 days. Early fall and late winter are generally dry; February's average of 2.64 inches (67 mm) makes it the area's driest month. The dewpoint in the summer averages between 59.1 °F (15 °C) to 64.5 °F (18 °C).\n",
      "Guam's climate is characterized as tropical marine moderated by seasonal northeast trade winds. The weather is generally very warm and humid with little seasonal temperature variation. The mean high temperature is 86 °F (30 °C) and mean low is 76 °F (24 °C) with an average annual rainfall of 96 inches (2,180 mm). The dry season runs from December to June. The remaining months (July to November) constitute the rainy season. The months of January and February are considered the coolest months of the year with overnight low temperatures of 70–75 °F (21–24 °C) and low humidity levels. The highest temperature ever recorded in Guam was 96 °F (36 °C) on April 18, 1971 and April 1, 1990, and the lowest temperature ever recorded was 65 °F (18 °C) on February 8, 1973.\n",
      "Summers in the state are generally hot and humid, with most of the state averaging a high of around 90 °F (32 °C) during the summer months. Winters tend to be mild to cool, increasing in coolness at higher elevations. Generally, for areas outside the highest mountains, the average overnight lows are near freezing for most of the state. The highest recorded temperature is 113 °F (45 °C) at Perryville on August 9, 1930 while the lowest recorded temperature is −32 °F (−36 °C) at Mountain City on December 30, 1917.\n",
      "Muammar Muhammad Abu Minyar al-Gaddafi (Arabic: معمر محمد أبو منيار القذافي‎ Arabic pronunciation: [muʕamar al.qaðaːfiː]; /ˈmoʊ.əmɑːr ɡəˈdɑːfi/;  audio (help·info); c. 1942 – 20 October 2011), commonly known as Colonel Gaddafi,[b] was a Libyan revolutionary, politician, and political theorist. He governed Libya as Revolutionary Chairman of the Libyan Arab Republic from 1969 to 1977 and then as the \"Brotherly Leader\" of the Great Socialist People's Libyan Arab Jamahiriya from 1977 to 2011. Initially ideologically committed to Arab nationalism and Arab socialism, he came to rule according to his own Third International Theory before embracing Pan-Africanism and serving as Chairperson of the African Union from 2009 to 2010.\n",
      "Cyprus has one of the warmest climates in the Mediterranean part of the European Union.[citation needed] The average annual temperature on the coast is around 24 °C (75 °F) during the day and 14 °C (57 °F) at night. Generally, summers last about eight months, beginning in April with average temperatures of 21–23 °C (70–73 °F) during the day and 11–13 °C (52–55 °F) at night, and ending in November with average temperatures of 22–23 °C (72–73 °F) during the day and 12–14 °C (54–57 °F) at night, although in the remaining four months temperatures sometimes exceed 20 °C (68 °F).\n",
      "Among all cities in the Mediterranean part of the European Union, Limassol has one of the warmest winters, in the period January – February average temperature is 17–18 °C (63–64 °F) during the day and 7–8 °C (45–46 °F) at night, in other coastal locations in Cyprus is generally 16–17 °C (61–63 °F) during the day and 6–8 °C (43–46 °F) at night. During March, Limassol has average temperatures of 19–20 °C (66–68 °F) during the day and 9–11 °C (48–52 °F) at night, in other coastal locations in Cyprus is generally 17–19 °C (63–66 °F) during the day and 8–10 °C (46–50 °F) at night.\n",
      "The middle of summer is hot – in July and August on the coast the average temperature is usually around 33 °C (91 °F) during the day and around 22 °C (72 °F) at night (inland, in the highlands average temperature exceeds 35 °C (95 °F)) while in the June and September on the coast the average temperature is usually around 30 °C (86 °F) during the day and around 20 °C (68 °F) at night in Limassol, while is usually around 28 °C (82 °F) during the day and around 18 °C (64 °F) at night in Paphos. Large fluctuations in temperature are rare. Inland temperatures are more extreme, with colder winters and hotter summers compared with the coast of the island.\n",
      "The highest temperature recorded within city limits was 104 °F (40 °C), on June 2, 1985, and June 24, 1944, and the lowest was 7 °F (−14 °C) on February 14, 1899, although at the airport, where official records are kept, the historical range is 105 °F (41 °C) on August 1, 1999 down to 6 °F (−14 °C) on January 21, 1985. Hurricanes are a major threat to the area during the summer and early fall, with several severe hurricanes hitting the area – most notably Hurricane Hugo on September 21, 1989 (a category 4 storm). Dewpoint in the summer ranges from 67.8 to 71.4 °F (20 to 22 °C).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The period between the foundation of the Han dynasty and Wang Mang's reign is known as the Western Han dynasty (simplified Chinese: 西汉; traditional Chinese: 西漢; pinyin: Xī Hàn) or Former Han dynasty (simplified Chinese: 前汉; traditional Chinese: 前漢; pinyin: Qiánhàn) (206 BC – 9 AD). During this period the capital was at Chang'an (modern Xi'an). From the reign of Guangwu the capital was moved eastward to Luoyang. The era from his reign until the fall of Han is known as the Eastern Han dynasty (simplified Chinese: 东汉; traditional Chinese: 東漢; pinyin: Dōng Hàn) or the Later Han dynasty (simplified Chinese: 后汉; traditional Chinese: 後漢; pinyin: Hòu Hàn) (25–220 AD).\n",
      "Hyderabad has a tropical wet and dry climate (Köppen Aw) bordering on a hot semi-arid climate (Köppen BSh). The annual mean temperature is 26.6 °C (79.9 °F); monthly mean temperatures are 21–33 °C (70–91 °F). Summers (March–June) are hot and humid, with average highs in the mid-to-high 30s Celsius; maximum temperatures often exceed 40 °C (104 °F) between April and June. The coolest temperatures occur in December and January, when the lowest temperature occasionally dips to 10 °C (50 °F). May is the hottest month, when daily temperatures range from 26 to 39 °C (79–102 °F); December, the coldest, has temperatures varying from 14.5 to 28 °C (57–82 °F).\n",
      "Winters in Tucson are mild relative to other parts of the United States. Daytime highs in the winter range between 64 and 75 °F (18 and 24 °C), with overnight lows between 30 and 44 °F (−1 and 7 °C). Tucson typically averages one hard freeze per winter season, with temperatures dipping to the mid or low-20s (−7 to −4 °C), but this is typically limited to only a very few nights. Although rare, snow has been known to fall in Tucson, usually a light dusting that melts within a day. The most recent snowfall was on February 20, 2013 when 2.0 inches of snow blanketed the city, the largest snowfall since 1987.\n",
      "At the University of Arizona, where records have been kept since 1894, the record maximum temperature was 115 °F (46 °C) on June 19, 1960, and July 28, 1995, and the record minimum temperature was 6 °F (−14 °C) on January 7, 1913. There are an average of 150.1 days annually with highs of 90 °F (32 °C) or higher and an average of 26.4 days with lows reaching or below the freezing mark. Average annual precipitation is 11.15 in (283 mm). There is an average of 49 days with measurable precipitation. The wettest year was 1905 with 24.17 in (614 mm) and the driest year was 1924 with 5.07 in (129 mm). The most precipitation in one month was 7.56 in (192 mm) in July 1984. The most precipitation in 24 hours was 4.16 in (106 mm) on October 1, 1983. Annual snowfall averages 0.7 in (1.8 cm). The most snow in one year was 7.2 in (18 cm) in 1987. The most snow in one month was 6.0 in (15 cm) in January 1898 and March 1922.\n",
      "At the airport, where records have been kept since 1930, the record maximum temperature was 117 °F (47 °C) on June 26, 1990, and the record minimum temperature was 16 °F (−9 °C) on January 4, 1949. There is an average of 145.0 days annually with highs of 90 °F (32 °C) or higher and an average of 16.9 days with lows reaching or below the freezing mark. Measurable precipitation falls on an average of 53 days. The wettest year was 1983 with 21.86 in (555 mm) of precipitation, and the driest year was 1953 with 5.34 in (136 mm). The most rainfall in one month was 7.93 in (201 mm) in August 1955. The most rainfall in 24 hours was 3.93 in (100 mm) on July 29, 1958. Snow at the airport averages only 1.1 in (2.8 cm) annually. The most snow received in one year was 8.3 in (21 cm) and the most snow in one month was 6.8 in (17 cm) in December 1971.\n",
      "Richmond has a humid subtropical climate (Köppen Cfa), with hot and humid summers and generally cool winters. The mountains to the west act as a partial barrier to outbreaks of cold, continental air in winter; Arctic air is delayed long enough to be modified, then further warmed as it subsides in its approach to Richmond. The open waters of the Chesapeake Bay and Atlantic Ocean contribute to the humid summers and mild winters. The coldest weather normally occurs from late December to early February, and the January daily mean temperature is 37.9 °F (3.3 °C), with an average of 6.0 days with highs at or below the freezing mark. Downtown areas straddle the border between USDA Hardiness zones 7B and 8A, and temperatures seldom lower to 0 °F (−18 °C), with the most recent subzero (°F) reading occurring on January 28, 2000, when the temperature reached −1 °F (−18 °C). The July daily mean temperature is 79.3 °F (26.3 °C), and high temperatures reach or exceed 90 °F (32 °C) approximately 43 days out of the year; while 100 °F (38 °C) temperatures are not uncommon, they do not occur every year. Extremes in temperature have ranged from −12 °F (−24 °C) on January 19, 1940 up to 107 °F (42 °C) on August 6, 1918.[a]\n",
      "San Diego is one of the top-ten best climates in the Farmers' Almanac and is one of the two best summer climates in America as scored by The Weather Channel. Under the Köppen–Geiger climate classification system, the San Diego area has been variously categorized as having either a semi-arid climate (BSh in the original classification and BSkn in modified Köppen classification) or a Mediterranean climate (Csa and Csb). San Diego's climate is characterized by warm, dry summers and mild winters with most of the annual precipitation falling between December and March. The city has a mild climate year-round, with an average of 201 days above 70 °F (21 °C) and low rainfall (9–13 inches [230–330 mm] annually). Dewpoints in the summer months range from 57.0 °F (13.9 °C) to 62.4 °F (16.9 °C).\n",
      "The climate in San Diego, like most of Southern California, often varies significantly over short geographical distances resulting in microclimates. In San Diego, this is mostly because of the city's topography (the Bay, and the numerous hills, mountains, and canyons). Frequently, particularly during the \"May gray/June gloom\" period, a thick \"marine layer\" cloud cover will keep the air cool and damp within a few miles of the coast, but will yield to bright cloudless sunshine approximately 5–10 miles (8.0–16.1 km) inland. Sometimes the June gloom can last into July, causing cloudy skies over most of San Diego for the entire day. Even in the absence of June gloom, inland areas tend to experience much more significant temperature variations than coastal areas, where the ocean serves as a moderating influence. Thus, for example, downtown San Diego averages January lows of 50 °F (10 °C) and August highs of 78 °F (26 °C). The city of El Cajon, just 10 miles (16 km) inland from downtown San Diego, averages January lows of 42 °F (6 °C) and August highs of 88 °F (31 °C).\n",
      "Older letters of the Russian alphabet include ⟨ѣ⟩, which merged to ⟨е⟩ (/je/ or /ʲe/); ⟨і⟩ and ⟨ѵ⟩, which both merged to ⟨и⟩ (/i/); ⟨ѳ⟩, which merged to ⟨ф⟩ (/f/); ⟨ѫ⟩, which merged to ⟨у⟩ (/u/); ⟨ѭ⟩, which merged to ⟨ю⟩ (/ju/ or /ʲu/); and ⟨ѧ/⟨ѩ⟩⟩, which later were graphically reshaped into ⟨я⟩ and merged phonetically to /ja/ or /ʲa/. While these older letters have been abandoned at one time or another, they may be used in this and related articles. The yers ⟨ъ⟩ and ⟨ь⟩ originally indicated the pronunciation of ultra-short or reduced /ŭ/, /ĭ/.\n",
      "Miṣr (IPA: [mi̠sˤr] or Egyptian Arabic pronunciation: [mesˤɾ]; Arabic: مِصر‎) is the Classical Quranic Arabic and modern official name of Egypt, while Maṣr (IPA: [mɑsˤɾ]; Egyptian Arabic: مَصر) is the local pronunciation in Egyptian Arabic. The name is of Semitic origin, directly cognate with other Semitic words for Egypt such as the Hebrew מִצְרַיִם (Mitzráyim). The oldest attestation of this name for Egypt is the Akkadian 𒆳 𒈪 𒄑 𒊒 KURmi-iṣ-ru miṣru, related to miṣru/miṣirru/miṣaru, meaning \"border\" or \"frontier\".\n",
      "Brasília has a tropical savanna climate (Aw) according to the Köppen system, with two distinct seasons: the rainy season, from October to April, and a dry season, from May to September. The average temperature is 20.6 °C (69.1 °F). September, at the end of the dry season, has the highest average maximum temperature, 28.3 °C (82.9 °F), has major and minor lower maximum average temperature, of 25.1 °C (77.2 °F) and 12.9 °C (55.2 °F), respectively. Average temperatures from September through March are a consistent 22 °C (72 °F). With 247.4 mm (9.7 in), January is the month with the highest rainfall of the year, while June is the lowest, with only 8.7 mm (0.3 in).\n",
      "World War II (1939-1945) devastated the country's economy, but the high levels of economic growth that followed from 1950 to 1980 have been called the Greek economic miracle. From 2000 Greece saw high levels of GDP growth above the Eurozone average, peaking at 5.8% in 2003 and 5.7% in 2006. The subsequent Great Recession and Greek government-debt crisis, a central focus of the wider European debt crisis, plunged the economy into a sharp downturn, with real GDP growth rates of −0.3% in 2008, −4.3% in 2009, −5.5% in 2010, −9.1% in 2011, −7.3% in 2012 and −3.2% in 2013. In 2011, the country's public debt reached €356 billion (172% of nominal GDP). After negotiating the biggest debt restructuring in history with the private sector, Greece reduced its sovereign debt burden to €280 billion (137% of GDP) in the first quarter of 2012. Greece achieved a real GDP growth rate of 0.7% in 2014 after 6 years of economic decline, but fell back into recession in 2015.\n",
      "The city generally has a climate with warm days followed by cool nights and mornings. Unpredictable weather is expected, given that temperatures can drop to 1 °C (34 °F) or less during the winter. During a 2013 cold front, the winter temperatures of Kathmandu dropped to −4 °C (25 °F), and the lowest temperature was recorded on January 10, 2013, at −9.2 °C (15.4 °F). Rainfall is mostly monsoon-based (about 65% of the total concentrated during the monsoon months of June to August), and decreases substantially (100 to 200 cm (39 to 79 in)) from eastern Nepal to western Nepal. Rainfall has been recorded at about 1,400 millimetres (55.1 in) for the Kathmandu valley, and averages 1,407 millimetres (55.4 in) for the city of Kathmandu. On average humidity is 75%. The chart below is based on data from the Nepal Bureau of Standards & Meteorology, \"Weather Meteorology\" for 2005. The chart provides minimum and maximum temperatures during each month. The annual amount of precipitation was 1,124 millimetres (44.3 in) for 2005, as per monthly data included in the table above. The decade of 2000-2010 saw highly variable and unprecedented precipitation anomalies in Kathmandu. This was mostly due to the annual variation of the southwest monsoon.[citation needed] For example, 2003 was the wettest year ever in Kathmandu, totalling over 2,900 mm (114 in) of precipitation due to an exceptionally strong monsoon season. In contrast, 2001 recorded only 356 mm (14 in) of precipitation due to an extraordinarily weak monsoon season.\n"
     ]
    }
   ],
   "source": [
    "squad_examples, paragraphs = read_squad_examples(\"../AnsweringMachines/dataset/train-v1.1.json\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               unique_id,\n",
    "               example_index,\n",
    "               doc_span_index,\n",
    "               tokens,\n",
    "               token_to_orig_map,\n",
    "               token_is_max_context,\n",
    "               input_ids,\n",
    "               input_mask,\n",
    "               segment_ids,\n",
    "               start_position=None,\n",
    "               end_position=None,\n",
    "               is_impossible=None):\n",
    "        self.unique_id = unique_id\n",
    "        self.example_index = example_index\n",
    "        self.doc_span_index = doc_span_index\n",
    "        self.tokens = tokens\n",
    "        self.token_to_orig_map = token_to_orig_map\n",
    "        self.token_is_max_context = token_is_max_context\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.start_position = start_position\n",
    "        self.end_position = end_position\n",
    "        self.is_impossible = is_impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer, orig_answer_text):\n",
    "\n",
    "    \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
    "\n",
    "      # The SQuAD annotations are character based. We first project them to\n",
    "      # whitespace-tokenized words. But then after WordPiece tokenization, we can\n",
    "      # often find a \"better match\". For example:\n",
    "      #\n",
    "      #   Question: What year was John Smith born?\n",
    "      #   Context: The leader was John Smith (1895-1943).\n",
    "      #   Answer: 1895\n",
    "      #\n",
    "      # The original whitespace-tokenized answer will be \"(1895-1943).\". However\n",
    "      # after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match\n",
    "      # the exact answer, 1895.\n",
    "      #\n",
    "      # However, this is not always possible. Consider the following:\n",
    "      #\n",
    "      #   Question: What country is the top exporter of electornics?\n",
    "      #   Context: The Japanese electronics industry is the lagest in the world.\n",
    "      #   Answer: Japan\n",
    "      #\n",
    "      # In this case, the annotator chose \"Japan\" as a character sub-span of\n",
    "      # the word \"Japanese\". Since our WordPiece tokenizer does not split\n",
    "      # \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare\n",
    "      # in SQuAD, but does happen.\n",
    "    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n",
    "\n",
    "    for new_start in range(input_start, input_end + 1):\n",
    "        for new_end in range(input_end, new_start - 1, -1):\n",
    "            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n",
    "            if text_span == tok_answer_text:\n",
    "                return (new_start, new_end)\n",
    "\n",
    "    return (input_start, input_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_by_vocab(vocab, items):\n",
    "    \"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"\n",
    "    output = []\n",
    "    for item in items:\n",
    "        output.append(vocab[item])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokens_to_ids(vocab, tokens):\n",
    "    return convert_by_vocab(vocab, tokens)\n",
    "\n",
    "\n",
    "def convert_ids_to_tokens(inv_vocab, ids):\n",
    "    return convert_by_vocab(inv_vocab, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullTokenizer(object):\n",
    "    \"\"\"Runs end-to-end tokenziation.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_file, do_lower_case=True):\n",
    "        self.vocab = load_vocab()\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n",
    "        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        split_tokens = []\n",
    "        for token in self.basic_tokenizer.tokenize(text):\n",
    "            for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
    "                split_tokens.append(sub_token)\n",
    "\n",
    "        return split_tokens\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return convert_by_vocab(self.vocab, tokens)\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        return convert_by_vocab(self.inv_vocab, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
    "    \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
    "\n",
    "    # Because of the sliding window approach taken to scoring documents, a single\n",
    "    # token can appear in multiple documents. E.g.\n",
    "    #  Doc: the man went to the store and bought a gallon of milk\n",
    "    #  Span A: the man went to the\n",
    "    #  Span B: to the store and bought\n",
    "    #  Span C: and bought a gallon of\n",
    "    #  ...\n",
    "    #\n",
    "    # Now the word 'bought' will have two scores from spans B and C. We only\n",
    "    # want to consider the score with \"maximum context\", which we define as\n",
    "    # the *minimum* of its left and right context (the *sum* of left and\n",
    "    # right context will always be the same, of course).\n",
    "    #\n",
    "    # In the example the maximum context for 'bought' would be span C since\n",
    "    # it has 1 left context and 3 right context, while span B has 4 left context\n",
    "    # and 0 right context.\n",
    "    best_score = None\n",
    "    best_span_index = None\n",
    "    for (span_index, doc_span) in enumerate(doc_spans):\n",
    "        end = doc_span.start + doc_span.length - 1\n",
    "        if position < doc_span.start:\n",
    "            continue\n",
    "        if position > end:\n",
    "            continue\n",
    "        num_left_context = position - doc_span.start\n",
    "        num_right_context = end - position\n",
    "        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_span_index = span_index\n",
    "\n",
    "    return cur_span_index == best_span_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from progress.bar import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length=50\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
    "                                 doc_stride, max_query_length, is_training):\n",
    "                                 \n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    count = 0.0\n",
    "    unique_id = 1000000000\n",
    "    max_length = len(examples)\n",
    "    features = []\n",
    "    max_query_len = 0\n",
    "    max_text_length = 0\n",
    "    for (example_index, example) in enumerate(examples):\n",
    "        query_tokens = tokenizer.tokenize(example.question_text)\n",
    "\n",
    "        # cap queries to 64 tokens\n",
    "        if len(query_tokens) > max_query_length:\n",
    "            query_tokens = query_tokens[0:max_query_length]\n",
    "        if len(query_tokens) > max_query_len:\n",
    "            max_query_len = len(query_tokens)\n",
    "\n",
    "        tok_to_orig_index = []\n",
    "        orig_to_tok_index = []\n",
    "        all_doc_tokens = []\n",
    "        for (i, token) in enumerate(example.doc_tokens):\n",
    "            orig_to_tok_index.append(len(all_doc_tokens))\n",
    "            sub_tokens = tokenizer.tokenize(token)\n",
    "            for sub_token in sub_tokens:\n",
    "                tok_to_orig_index.append(i)\n",
    "                all_doc_tokens.append(sub_token)\n",
    "\n",
    "        tok_start_position = None\n",
    "        tok_end_position = None\n",
    "        if is_training and example.is_impossible:\n",
    "            tok_start_position = -1\n",
    "            tok_end_position = -1\n",
    "        if is_training and not example.is_impossible:\n",
    "            tok_start_position = orig_to_tok_index[example.start_position]\n",
    "            if example.end_position < len(example.doc_tokens) - 1:\n",
    "                tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n",
    "            else:\n",
    "                tok_end_position = len(all_doc_tokens) - 1\n",
    "            (tok_start_position, tok_end_position) = _improve_answer_span(\n",
    "                all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n",
    "                example.orig_answer_text)\n",
    "\n",
    "        # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "        max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
    "\n",
    "        # We can have documents that are longer than the maximum sequence length.\n",
    "        # To deal with this we do a sliding window approach, where we take chunks\n",
    "        # of the up to our max length with a stride of `doc_stride`.\n",
    "        _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "            \"DocSpan\", [\"start\", \"length\"])\n",
    "        doc_spans = []\n",
    "        start_offset = 0\n",
    "        while start_offset < len(all_doc_tokens):\n",
    "            length = len(all_doc_tokens) - start_offset\n",
    "            if length > max_tokens_for_doc:\n",
    "                length = max_tokens_for_doc\n",
    "            doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "            if start_offset + length == len(all_doc_tokens):\n",
    "                break\n",
    "            start_offset += min(length, doc_stride)\n",
    "\n",
    "        # each input is: [CLS] [Qt] [Qt] [SEP] [Tt] [Tt]\n",
    "        # where [Qt]s are tokens from query\n",
    "        # and [Tt]s are tokens from the text\n",
    "        for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "            tokens = []\n",
    "            token_to_orig_map = {}\n",
    "            token_is_max_context = {}\n",
    "            segment_ids = []\n",
    "            tokens.append(\"[CLS]\")\n",
    "            segment_ids.append(0)\n",
    "            for token in query_tokens:\n",
    "                tokens.append(token)\n",
    "                segment_ids.append(0)\n",
    "            tokens.append(\"[SEP]\")\n",
    "            segment_ids.append(0)\n",
    "\n",
    "            for i in range(doc_span.length):\n",
    "                split_token_index = doc_span.start + i\n",
    "                token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
    "\n",
    "                is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
    "                                               split_token_index)\n",
    "                token_is_max_context[len(tokens)] = is_max_context\n",
    "                tokens.append(all_doc_tokens[split_token_index])\n",
    "                segment_ids.append(1)\n",
    "            tokens.append(\"[SEP]\")\n",
    "            segment_ids.append(1)\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            input_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            while len(input_ids) < max_seq_length:\n",
    "                input_ids.append(0)\n",
    "                input_mask.append(0)\n",
    "                segment_ids.append(0)\n",
    "\n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "\n",
    "            start_position = None\n",
    "            end_position = None\n",
    "            if is_training and not example.is_impossible:\n",
    "                # For training, if our document chunk does not contain an annotation\n",
    "                # we throw it out, since there is nothing to predict.\n",
    "                doc_start = doc_span.start\n",
    "                doc_end = doc_span.start + doc_span.length - 1\n",
    "                out_of_span = False\n",
    "                if not (tok_start_position >= doc_start and\n",
    "                        tok_end_position <= doc_end):\n",
    "                    out_of_span = True\n",
    "                if out_of_span:\n",
    "                    start_position = 0\n",
    "                    end_position = 0\n",
    "                else:\n",
    "                    doc_offset = len(query_tokens) + 2\n",
    "                    start_position = tok_start_position - doc_start + doc_offset\n",
    "                    end_position = tok_end_position - doc_start + doc_offset\n",
    "\n",
    "            if is_training and example.is_impossible:\n",
    "                start_position = 0\n",
    "                end_position = 0\n",
    "\n",
    "            if example_index < 0:\n",
    "                print(\"*** Example ***\")\n",
    "                print(\"unique_id: %s\" % (unique_id))\n",
    "                print(\"example_index: %s\" % (example_index))\n",
    "                print(\"doc_span_index: %s\" % (doc_span_index))\n",
    "                print(\"tokens: %s\" % \" \".join(\n",
    "                    [printable_text(x) for x in tokens]))\n",
    "                print(\"token_to_orig_map: %s\" % \" \".join(\n",
    "                    [\"%d:%d\" % (x, y) for (x, y) in six.iteritems(token_to_orig_map)]))\n",
    "                print(\"token_is_max_context: %s\" % \" \".join([\n",
    "                    \"%d:%s\" % (x, y) for (x, y) in six.iteritems(token_is_max_context)\n",
    "                    ]))\n",
    "                print(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "                print(\n",
    "                    \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "                print(\n",
    "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "                if is_training and example.is_impossible:\n",
    "                    print(\"impossible example\")\n",
    "                if is_training and not example.is_impossible:\n",
    "                    answer_text = \" \".join(tokens[start_position:(end_position + 1)])\n",
    "                    print(\"start_position: %d\" % (start_position))\n",
    "                    print(\"end_position: %d\" % (end_position))\n",
    "                    print(\n",
    "                        \"answer: %s\" % (printable_text(answer_text)))\n",
    "\n",
    "            feature = InputFeatures(\n",
    "                    unique_id=unique_id,\n",
    "                    example_index=example_index,\n",
    "                    doc_span_index=doc_span_index,\n",
    "                    tokens=tokens,\n",
    "                    token_to_orig_map=token_to_orig_map,\n",
    "                    token_is_max_context=token_is_max_context,\n",
    "                    input_ids=input_ids,\n",
    "                    input_mask=input_mask,\n",
    "                    segment_ids=segment_ids,\n",
    "                    start_position=start_position,\n",
    "                    end_position=end_position,\n",
    "                    is_impossible=example.is_impossible)\n",
    "\n",
    "            features.append(feature)\n",
    "            # Run callback\n",
    "            #output_fn(feature)\n",
    "\n",
    "        unique_id += 1\n",
    "        count += 1.0\n",
    "        if (count % 1000) == 0:\n",
    "            update_progress(count/max_length)\n",
    "\n",
    "    print(\"{} queries were greater than 64 tokens\".format(num_queries_greater))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(\"/Users/vijay/MIDS/w266/Project/BERT/uncased_L-12_H-768_A-12/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##################################################] 99.3%\n",
      "49 queries were greater than 64 tokens\n"
     ]
    }
   ],
   "source": [
    "features = convert_examples_to_features(squad_examples, tokenizer, 384, 128, 32, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88152"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_features = features[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = len(reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_squad = np.ndarray(shape=(max_features,384,300), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "for i, f in enumerate(reduced_features):\n",
    "    f_vector = [ ]\n",
    "    for _id in f.input_ids:\n",
    "        w = inv_vocab[_id]\n",
    "        f_vector.append(embedding_dict[w])\n",
    "    v = np.asarray(f_vector)\n",
    "    X_squad[i-1] = v\n",
    "    update_progress(i/max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 384, 300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_squad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_squad = np.ndarray(shape=(max_features,384), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 300)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "for i, f in enumerate(reduced_features):\n",
    "    y = np.zeros((384,))\n",
    "    y[f.start_position] = 1.0\n",
    "    y_squad[i-1] = y\n",
    "    update_progress(i/max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_squad[:4000]\n",
    "X_test = X_squad[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_squad[:4000]\n",
    "y_test = y_squad[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[384, 300]),\n",
    "        keras.layers.Dropout(rate=0.5),\n",
    "        keras.layers.Dense(600, activation='relu'),\n",
    "        keras.layers.Dense(384, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 600)               69120600  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 384)               230784    \n",
      "=================================================================\n",
      "Total params: 69,351,384\n",
      "Trainable params: 69,351,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3392/4000 [========================>.....] - ETA: 21s - loss: 15.9613 - acc: 0.0097"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-1e51fab1ab6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s 5ms/sample - loss: 5.2082 - acc: 0.0120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.2082183494567875, 0.012]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
